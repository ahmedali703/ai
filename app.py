from flask import Flask, request, jsonify, render_template, session
from flask_session import Session
import redis
from flask_cors import CORS
import oracledb
import os
import re
import uuid
import schedule
import time
from sqlalchemy import create_engine, MetaData, Column, Integer, String, ForeignKey, DateTime, Text
from sqlalchemy.orm import sessionmaker, declarative_base, relationship
import datetime
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from deep_translator import GoogleTranslator
from openai import OpenAI  # Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¹Ù…ÙŠÙ„ Ù…Ù† Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ø¬Ø¯ÙŠØ¯
from dotenv import load_dotenv
import sys
import io
import threading
import numpy as np
import json
import traceback
from werkzeug.security import generate_password_hash, check_password_hash
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
import smtplib
from apscheduler.schedulers.background import BackgroundScheduler
from datetime import datetime
import subprocess
import secrets


# ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© Ù…Ù† Ù…Ù„Ù .env (Ø¥Ù† ÙˆØ¬Ø¯)
load_dotenv()

app = Flask(__name__)
CORS(app, supports_credentials=True)  


# scheduler = BackgroundScheduler()
# scheduler.start()


# Ø¥Ø¹Ø¯Ø§Ø¯ Ù…ÙØªØ§Ø­ Ø³Ø±ÙŠ Ù„Ù„Ø¬Ù„Ø³Ø§Øª
app.secret_key = os.getenv("SECRET_KEY", secrets.token_hex(32))  # Ù…ÙØªØ§Ø­ Ø¢Ù…Ù†

# Ø¥Ø¹Ø¯Ø§Ø¯ Flask-Session Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Redis
app.config["SESSION_TYPE"] = "redis"
app.config["SESSION_REDIS"] = redis.from_url("redis://localhost:6379") 
app.config["SESSION_PERMANENT"] = False
app.config["SESSION_USE_SIGNER"] = True

Session(app)

# ===== Ø¥Ø¹Ø¯Ø§Ø¯ Ø§ØªØµØ§Ù„ Ø£ÙˆØ±Ø§ÙƒÙ„ =====
os.environ["NLS_LANG"] = "AMERICAN_AMERICA.AL32UTF8"
os.environ["TNS_ADMIN"] = r"C:\app\Mopa\product\21c\dbhomeXE\instantclient"

try:
    connection = oracledb.connect(
        user=os.getenv("ORACLE_USER", "HR"),
        password=os.getenv("ORACLE_PASSWORD", "HR"),
        dsn=os.getenv("ORACLE_DSN", "localhost/xepdb1")  # ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù€ SID Ø£Ùˆ Service Name
    )
    print("Successfully connected to Oracle database.")
except Exception as e:
    print(f"Error connecting to Oracle database: {e}")
    connection = None

# SQLAlchemy
# Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù€ Service Name ÙÙŠ Ø³Ù„Ø³Ù„Ø© Ø§Ù„Ø§ØªØµØ§Ù„
engine = create_engine(os.getenv("SQLALCHEMY_DATABASE_URI", "oracle+oracledb://HR:HR@localhost/?service_name=xepdb1"))
SessionLocal = sessionmaker(bind=engine)
metadata = MetaData()
Base = declarative_base()

# Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
class User(Base):
    __tablename__ = 'users'
    
    id = Column(Integer, primary_key=True, index=True)
    username = Column(String(50), unique=True, nullable=False)
    password = Column(String(255), nullable=False)

    # ØªØ¹Ø±ÙŠÙ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
class Conversation(Base):
    __tablename__ = 'conversations'
    conversation_id = Column(Integer, primary_key=True, index=True)
    user_id = Column(Integer, ForeignKey('users.id'), nullable=False)
    question = Column(Text, nullable=False)  # ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Text Ø£Ùˆ CLOB Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©
    response = Column(Text, nullable=False)
    timestamp = Column(DateTime, default=datetime.utcnow)
    feedback = Column(Text)  # Ø­Ù‚Ù„ Ù†ØµÙŠ Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª
    classification = Column(String(100))  # Ø§Ù„Ø­Ù‚Ù„ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„ØªØµÙ†ÙŠÙ

    user = relationship("User", backref="conversations")

# ØªØ¹Ø±ÙŠÙ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø©
class Feedback(Base):
    __tablename__ = 'feedback'
    feedback_id = Column(Integer, primary_key=True, index=True)
    conversation_id = Column(Integer, ForeignKey('conversations.conversation_id'), nullable=False)
    rating_type = Column(Integer)  # ØªÙ‚ÙŠÙŠÙ… Ø±Ù‚Ù…ÙŠ Ù…Ø«Ù„Ù‹Ø§ Ù…Ù† 1 Ø¥Ù„Ù‰ 5
    comments = Column(Text)  # Ø­Ù‚Ù„ Ù†ØµÙŠ Ù„Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª

    conversation = relationship("Conversation", backref="feedbacks")


# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø©
Base.metadata.create_all(bind=engine)

# Ø¥Ø¹Ø¯Ø§Ø¯ OpenAI
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))  # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø§Ù„Ø¬Ø¯ÙŠØ¯

smtplib.debuglevel = 1


# ====================================================================
# Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©
# ====================================================================

def save_conversation(user_id, question, response, classification, feedback=None):
    try:
        db_session = SessionLocal()
        new_conversation = Conversation(
            user_id=user_id,
            question=question,
            response=response,
            feedback=feedback,
            classification=classification# Ø­ÙØ¸ Ø§Ù„ØªØµÙ†ÙŠÙ
        )
        db_session.add(new_conversation)
        db_session.commit()
        db_session.refresh(new_conversation)
        db_session.close()
        return new_conversation.conversation_id
    except Exception as e:
        print(f"Error saving conversation: {e}")
        if db_session:
            db_session.rollback()
            db_session.close()
        return None


import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans

def fetch_all_data():
    db_session = SessionLocal()
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª
    conversations = db_session.query(Conversation).all()
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø©
    feedbacks = db_session.query(Feedback).all()
    db_session.close()

    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø¥Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ù‚ÙˆØ§Ù…ÙŠØ³
    conv_data = [{
        "conversation_id": conv.conversation_id,
        "user_id": conv.user_id,
        "question": conv.question,
        "response": conv.response,
        "timestamp": conv.timestamp,
        "feedback": conv.feedback
    } for conv in conversations]

    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø© Ø¥Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ù‚ÙˆØ§Ù…ÙŠØ³
    feedback_data = [{
        "feedback_id": fb.feedback_id,
        "conversation_id": fb.conversation_id,
        "rating_type": fb.rating_type,
        "comments": fb.comments
    } for fb in feedbacks]

    return conv_data, feedback_data

def analyze_question_patterns():
    conv_data, _ = fetch_all_data()
    df_conversations = pd.DataFrame(conv_data)

    # ØªØ¬Ù‡ÙŠØ² Ù†Øµ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØªØ­ÙˆÙŠÙ„Ù‡ Ø¥Ù„Ù‰ Ù…ØªØ¬Ù‡Ø§Øª
    vectorizer = TfidfVectorizer(stop_words='arabic')
    X = vectorizer.fit_transform(df_conversations['question'].astype(str))

    # ØªØ·Ø¨ÙŠÙ‚ KMeans Ù„Ù„ØªØ¬Ù…ÙŠØ¹
    n_clusters = 5
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    kmeans.fit(X)

    df_conversations['cluster'] = kmeans.labels_
    pattern_counts = df_conversations['cluster'].value_counts()
    print("Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹Ø§Ù‹:\n", pattern_counts)


# Ø¯Ø§Ù„Ø© Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ Ø¨ØµÙŠØºØ© HTML
def send_email_html(to_addresses, subject, html_body, smtp_server="apexexperts.net", smtp_port=465, username="ai@apexexperts.net", password="Ahmed@_240615"):
    msg = MIMEText(html_body, "html", "utf-8")
    msg = MIMEMultipart()
    msg["Subject"] = subject
    msg["From"] = username
    # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©ØŒ Ù‚Ù… Ø¨ØªØ¬Ù…ÙŠØ¹Ù‡Ø§ Ù„Ø±Ø£Ø³ Ø§Ù„Ø±Ø³Ø§Ù„Ø©
    if isinstance(to_addresses, list):
        msg["To"] = ", ".join(to_addresses)
    else:
        msg["To"] = to_addresses
    msg.attach(MIMEText(html_body, "html", "utf-8"))
    try:
        server = smtplib.SMTP_SSL(smtp_server, smtp_port)
        server.login(username, password)
        server.sendmail(username, to_addresses if isinstance(to_addresses, list) else [to_addresses], msg.as_string())
        server.quit()
        return True
    except Exception as e:
        print(f"Error sending email: {e}")
        return False

def send_weekly_report():
    subject = "Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ"
    body = "<h1>Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ</h1><p>Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ.</p>"
    to_email = "ahmed-alsaied@msn.com"
    send_email_html(to_email, subject, body)

def send_weekly_report_with_chart():
    subject = "Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ Ù…Ø¹ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ"
    body = "<h1>Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ</h1><p>Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ.</p>"
    to_email = "recipient@example.com"
    send_email_html(to_email, subject, body)

def dicts_to_html_table(data):
    if not data:
        return "<p>Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª.</p>"
    df = pd.DataFrame(data)
    # ØªØ­ÙˆÙŠÙ„ DataFrame Ø¥Ù„Ù‰ HTML Ù…Ø¹ ØªÙ†Ø³ÙŠÙ‚Ø§Øª Ø¨Ø³ÙŠØ·Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Tailwind CSS
    return df.to_html(classes="min-w-full bg-white border border-gray-200 rounded-lg text-center", index=False)


def get_all_table_schemas():
    if not connection:
        print("No database connection.")
        return ""
    try:
        with connection.cursor() as cursor:
            cursor.execute("""
                SELECT TABLE_NAME, COLUMN_NAME, DATA_TYPE
                FROM ALL_TAB_COLUMNS
                WHERE OWNER = 'HR'
                ORDER BY TABLE_NAME, COLUMN_ID
            """)
            rows = cursor.fetchall()
        table_schemas = {}
        for row in rows:
            table, column, data_type = row
            if table not in table_schemas:
                table_schemas[table] = []
            table_schemas[table].append(f"{column} ({data_type})")
        schema_summary = ""
        for table, columns in table_schemas.items():
            schema_summary += f"\nTable {table} has the following columns:\n"
            for col in columns:
                schema_summary += f"- {col}\n"
        return schema_summary
    except Exception as e:
        print(f"Error fetching table schemas: {e}")
        return ""

def classify_question(question):
    """
    ÙŠØµÙ†Ù Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¥Ù„Ù‰ Ø£Ø­Ø¯ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ø£Ø±Ø¨Ø¹Ø©:
    - 'db_sql'    : Ø§Ø³ØªØ¹Ù„Ø§Ù… SQL Ø¹Ø§Ø¯ÙŠ (SELECT)
    - 'db_analysis': ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù…/Ø¥Ø­ØµØ§Ø¦ÙŠ
    - 'db_action' : Ø£ÙˆØ§Ù…Ø± ØªØ¹Ø¯ÙŠÙ„ (INSERT / UPDATE / DELETE)
    - 'general'   : Ø³Ø¤Ø§Ù„ Ø¹Ø§Ù…
    """

    question_lower = question.lower().strip()

    # ===== Ù…ÙØ§ØªÙŠØ­ Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ (Action) =====
    action_keywords = [
        "insert", "update", "delete", "remove", "add", "create record", "create table",
        "send mail", "create restful services",
        "drop", "truncate", "Ø§Ù†Ø´Ø§Ø¡", "Ø¥Ø¶Ø§ÙØ©", "Ø­Ø°Ù", "ØªØ­Ø¯ÙŠØ«", 
        "ØªØ¹Ø¯ÙŠÙ„", "add column", "rename"
    ]

    # ===== Ù…ÙØ§ØªÙŠØ­ ØªØ­Ù„ÙŠÙ„ÙŠØ© (Analysis) =====
    analysis_keywords = [
        "ØªØ­Ù„ÙŠÙ„", "Ø§Ø­ØµØ§Ø¡", "Ø¥Ø­ØµØ§Ø¡", "Ø¥Ø­ØµØ§Ø¦ÙŠ",
        "analysis", "statistic", "statistics", "describe",
        "distribution", "mean", "histogram", "correlation",
        "boxplot", "Ø§Ù†Ø­Ø±Ø§Ù Ù…Ø¹ÙŠØ§Ø±ÙŠ", "variance", "standard deviation",
        "summarize", "summary", "trend", "forecast", "regression",
        "analyze", "aggregate", "pivot"
    ]

    # ===== Ù…ÙØ§ØªÙŠØ­ SQL (Reading) =====
    db_sql_keywords = [
        "select", "show me", "fetch", "retrieve",
        "Ø§Ø³ØªØ¹Ù„Ø§Ù…", "query", "Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙˆÙ„", "Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©",
        "sum", "Ù…Ø¬Ù…ÙˆØ¹", "Ø§Ø¬Ù…Ø§Ù„ÙŠ", "Ø¥Ø¬Ù…Ø§Ù„ÙŠ", "Ù…ØªÙˆØ³Ø·",
        "maximum", "minimum", "order by", "limit",
        "Ø¹Ø±Ø¶", "Ø§Ø¸Ù‡Ø§Ø±", "columns"
    ]

    # ===== Ù…ÙØ§ØªÙŠØ­ Ø£Ø³Ø¦Ù„Ø© Ø¹Ø§Ù…Ø© (General) =====
    general_keywords = [
        "what is", "explain", "why", "how to", "ÙƒÙŠÙÙŠØ©",
        "Ø¹Ø§Ù…", "Ù…Ø¹Ù„ÙˆÙ…Ø©", "what are", "Ù…ØªÙ‰", "Ø£ÙŠÙ†", "Ù„Ù…Ø§Ø°Ø§"
    ]

    # 1) Ù„Ùˆ Ø±ØµØ¯Ù†Ø§ action_keywords
    for ak in action_keywords:
        if ak in question_lower:
            print("Local classification => db_action")
            return "db_action"

    # 2) Ù„Ùˆ Ø±ØµØ¯Ù†Ø§ analysis
    for kw in analysis_keywords:
        if kw in question_lower:
            print("Local classification => db_analysis")
            return "db_analysis"

    # 3) Ù„Ùˆ Ø±ØµØ¯Ù†Ø§ db_sql
    for kw in db_sql_keywords:
        if kw in question_lower:
            print("Local classification => db_sql")
            return "db_sql"

    # 4) Ù„Ùˆ Ø±ØµØ¯Ù†Ø§ general_keywords
    for kw in general_keywords:
        if kw in question_lower:
            print("Local classification => general")
            return "general"

    # 5) Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¹Ø«Ø± Ø¹Ù„Ù‰ ØªØµÙ†ÙŠÙ ÙˆØ§Ø¶Ø­ Ù…Ø­Ù„ÙŠÙ‹Ø§ => Ù†Ù„Ø¬Ø£ Ù„Ù€GPT
    try:
        schema_summary = get_all_table_schemas()  # ÙŠÙØªØ±Ø¶ Ø£Ù†Ù‡Ø§ Ø¯Ø§Ù„Ø© Ù„Ø¯ÙŠÙƒ ØªØ¹ÙŠØ¯ ÙˆØµÙ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
        prompt = f"""
You are a classification assistant. You have the following database schema:

{schema_summary}

You must classify any user question into exactly one category:
1) db_sql: direct query about the database, e.g. SELECT, retrieving rows/columns directly, "Show me employees"
2) db_analysis: advanced analysis or statistics on the data, e.g. "Calculate average salary or distribution"
3) db_action: modifying the database, e.g. "INSERT, UPDATE, DELETE, DROP, CREATE TABLE"
4) general: if not related to the HR database or no direct data/analysis request.

Important rules:
- If user question includes "INSERT", "UPDATE", "DELETE", "CREATE", "DROP", or similar, classify as db_action.
- If user question includes "mean, distribution, correlation, statistic", or advanced analysis terms, classify as db_analysis.
- If user question includes "select, show me, fetch, retrieve" from a table, or direct request of rows, classify as db_sql.
- If user question is unrelated to the HR schema, or is general knowledge, classify as general.
- Use EXACT category name: db_sql, db_analysis, db_action, or general. No extra words.

Examples:
1) "Add new column to EMPLOYEES" => db_action
2) "Compute average salary of employees" => db_analysis
3) "SELECT * from employees" => db_sql
4) "What is AI?" => general

Now, classify the user question below:

Question: "{question}"
Answer with exactly one of: db_sql, db_analysis, db_action, or general.
"""
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=3000,
            temperature=0
        )
        classification = response.choices[0].message.content.strip().lower()
        print(f"GPT classification => {classification}")

        if 'db_sql' in classification:
            return 'db_sql'
        elif 'db_analysis' in classification:
            return 'db_analysis'
        elif 'db_action' in classification:
            return 'db_action'
        else:
            return 'general'
    except Exception as e:
        print(f"Error classifying question with GPT: {e}")
        return 'general'

def translate_ar_to_en(text):
    try:
        print("Translating:", text)
        translated = GoogleTranslator(source='ar', target='en').translate(text)
        print("Translated:", translated)
        return translated
    except Exception as e:
        print(f"Translation error: {e}")
        return text

def clean_sql_query(sql_query):
    sql_query = sql_query.strip()
    sql_query = re.sub(r';$', '', sql_query)
    sql_query = re.sub(r'[Ø›Ø›]', '', sql_query)
    sql_query = sql_query.replace('\u200f', '')
    return sql_query

def natural_language_to_sql(question, is_chart=False):
    """
    ÙŠØ­ÙˆÙ„ Ø£Ø³Ø¦Ù„Ø© ØªØªØ¹Ù„Ù‚ Ø¨Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (SELECT) Ø¥Ù„Ù‰ Ø¬Ù…Ù„Ø© SQL.
    """
    try:
        question_en = translate_ar_to_en(question)
        schema_summary = get_all_table_schemas()

        if is_chart:
            prompt = f"""
Translate the following question into a SQL query that returns data suitable for a bar chart with two columns: 'label' and 'value'. Provide only the SQL code without any explanations or additional text. Do not include a semicolon at the end.

Here is the schema of the database:
{schema_summary}

Question: '{question_en}'
"""
        else:
            prompt = f"""
Translate the following question into a SQL query. Provide only the SQL code without any explanations or additional text. Do not include a semicolon at the end.

Here is the schema of the database:
{schema_summary}

Question: '{question_en}'
"""

        print(f"Sending prompt to OpenAI: {prompt}")
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "You are a helpful assistant that translates natural language questions into SQL queries compatible with Oracle Database."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=3000,
            temperature=0
        )
        sql_query = response.choices[0].message.content.strip()
        print(f"Generated SQL Query: {sql_query}")
        return clean_sql_query(sql_query)
    except Exception as e:
        print(f"Error generating SQL query: {e}")
        return None

def natural_language_to_dml_action(question):
    """
    ÙŠØ­ÙˆÙ‘Ù„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ (INSERT/UPDATE/DELETE)
    Ø¥Ù„Ù‰ Ø¬Ù…Ù„Ø© SQL Ø®Ø§ØµØ© Ø¨Ø§Ù„Ø£ÙƒØ´Ù†.
    """
    try:
        question_en = translate_ar_to_en(question)
        schema_summary = get_all_table_schemas()

        prompt = f"""
You are an Oracle database expert with the ability to execute any complex queries, as well as add, modify, and delete data. You have complete knowledge of all tables and data in the database and can provide effective solutions to any database-related issues. Your tasks include:

Executing complex SQL queries:

Writing queries to extract required data from tables.

Using JOIN, GROUP BY, HAVING, SUBQUERIES, and other advanced operations.

Optimizing queries to ensure optimal performance.

Managing data:

Adding new data to tables using INSERT.

Updating existing data using UPDATE.

Deleting data using DELETE.

Analyzing data:

Analyzing relationships between tables and understanding the database structure.

Identifying data issues and providing solutions to fix them.

Creating and modifying tables:

Creating new tables using CREATE TABLE.

Modifying table structures using ALTER TABLE.

Dropping tables using DROP TABLE.

Managing indexes:

Creating indexes to improve query performance.

Analyzing existing indexes and determining the need for modifications.

Providing reports and results:

Delivering clear and organized results for queries.

Generating reports summarizing the required data.

Troubleshooting:

Analyzing errors in queries and fixing them.

Providing solutions for any issues related to data integrity or performance.

You are familiar with all tables, columns, and relationships between them, and you can provide accurate and effective answers to any questions or requests related to Oracle databases.

Database schema:
{schema_summary}

User request: '{question_en}'
"""

        print(f"Sending 'action' prompt to OpenAI:\n{prompt}")
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "You are an assistant that writes Oracle-compatible DML statements."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=3000,
            temperature=0
        )
        action_sql = response.choices[0].message.content.strip()
        print(f"Generated DML SQL: {action_sql}")
        return clean_sql_query(action_sql)
    except Exception as e:
        print(f"Error generating DML action: {e}")
        return None

def execute_sql_query(sql_query):
    """
    ÙŠÙ†ÙÙ‘Ø° Ø§Ø³ØªØ¹Ù„Ø§Ù… SELECT Ø¹Ù„Ù‰ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙŠØ¹ÙŠØ¯ DataFrame.
    """
    if not connection:
        print("No database connection.")
        return None
    try:
        with connection.cursor() as cursor:
            print(f"Executing SQL Query: {sql_query}")
            cursor.execute(sql_query)
            rows = cursor.fetchall()
            columns = [desc[0] for desc in cursor.description]
            df = pd.DataFrame(rows, columns=columns)
            df = df.fillna(0)  # Ù…Ù„Ø¡ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ§Ø±ØºØ©
            # ØªÙˆØ­ÙŠØ¯ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
            new_columns = []
            for col in df.columns:
                clean_col = col.replace(" ", "_").upper()
                new_columns.append(clean_col)
            df.columns = new_columns
            print(f"New Columns after cleaning: {df.columns.tolist()}")
        print(f"Query Results: {df}")
        return df
    except Exception as e:
        print(f"Error executing SQL query: {e}")
        return None

def execute_sql_action(sql_statement):
    """
    ÙŠÙ†ÙÙ‘Ø° (INSERT / UPDATE / DELETE) Ø¹Ù„Ù‰ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙŠØ¹Ù…Ù„ commit.
    ÙŠØ¹ÙŠØ¯ (success, message, rows_affected).
    """
    if not connection:
        print("No database connection.")
        return False, "No DB connection", 0
    try:
        with connection.cursor() as cursor:
            print(f"Executing SQL Action: {sql_statement}")
            cursor.execute(sql_statement)
            rows_affected = cursor.rowcount  # Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù…ØªØ£Ø«Ø±Ø©
            connection.commit()
        return True, "ØªÙ… ØªÙ†ÙÙŠØ° Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­", rows_affected
    except Exception as e:
        print(f"Error executing SQL action: {e}")
        return False, str(e), 0

def get_salary_summary():
    """
    Ù…Ø«Ø§Ù„ Ø¨Ø³ÙŠØ·: Ø§Ø³ØªØ¹Ù„Ø§Ù… ÙŠÙØ¹ÙŠØ¯ (MIN(SALARY), MAX(SALARY), AVG(SALARY), COUNT(*))
    ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø­Ø³Ø¨ Ù…Ø§ ØªØ±ÙŠØ¯ ØªÙ„Ø®ÙŠØµÙ‡.
    """
    if not connection:
        return {}
    try:
        with connection.cursor() as cursor:
            cursor.execute("SELECT MIN(SALARY), MAX(SALARY), AVG(SALARY), COUNT(*) FROM EMPLOYEES")
            row = cursor.fetchone()
            if row:
                min_sal, max_sal, avg_sal, cnt = row
                return {
                    "min_salary": float(min_sal or 0),
                    "max_salary": float(max_sal or 0),
                    "avg_salary": float(avg_sal or 0),
                    "total_employees": int(cnt or 0)
                }
    except:
        pass
    return {}

def generate_chart(data, x_key, y_key):
    plt.figure(figsize=(10, 6))
    plt.bar(data[x_key], data[y_key], color='skyblue')
    plt.xlabel(x_key)
    plt.ylabel(y_key)
    plt.title(f"Sum of {y_key} by {x_key}")
    plt.xticks(rotation=45)
    plt.tight_layout()
    chart_path = f"./static/charts/{uuid.uuid4().hex}.png"
    os.makedirs(os.path.dirname(chart_path), exist_ok=True)
    plt.savefig(chart_path)
    plt.close()
    return f"./static/charts/{os.path.basename(chart_path)}"

def remove_markdown_fences(code_text):
    code_text = re.sub(r"```python\s*", "", code_text)
    code_text = re.sub(r"```", "", code_text)
    return code_text

def exec_python_code(code, df):
    code = remove_markdown_fences(code)

    old_stdout = sys.stdout
    mystdout = io.StringIO()
    sys.stdout = mystdout

    local_env = {
        "df": df,
        "pd": pd,
        "np": np,
        "plt": plt
    }

    try:
        exec(code, local_env)
    except Exception as e:
        sys.stdout = old_stdout
        error_output = mystdout.getvalue()
        tb = traceback.format_exc()
        error_output += f"\n\nØ­Ø¯Ø« Ø§Ø³ØªØ«Ù†Ø§Ø¡:\n{str(e)}\nTraceback:\n{tb}"
        return f"Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªÙ†ÙÙŠØ° Ø§Ù„ÙƒÙˆØ¯:\n{error_output}", ""

    output = mystdout.getvalue()
    sys.stdout = old_stdout
    return "", output


def generate_response_with_context(question):
    conversation_history = session.get('conversation_history', [])
    context = " ".join([msg["content"] for msg in conversation_history])
    prompt = f"Ù…Ø¹ Ù…Ø±Ø§Ø¹Ø§Ø© Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„ØªØ§Ù„ÙŠ: {context}\nØ§Ù„Ø³Ø¤Ø§Ù„: {question}\nØ§Ù„Ø¥Ø¬Ø§Ø¨Ø©:"
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": prompt}
        ],
        max_tokens=3000,
        temperature=0
    )
    return response.choices[0].message.content.strip()


# ====================================================================
#             Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª
# ====================================================================

@app.route('/')
def home():
    return render_template('index.html')

@app.route('/register', methods=['POST'])
def register_user():
    try:
        data = request.get_json()
        username = data.get("username")
        password = data.get("password")
        if not username or not password:
            return jsonify({"error": "ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±"}), 400

        db = SessionLocal()
        existing_user = db.query(User).filter(User.username == username).first()
        if existing_user:
            return jsonify({"error": "Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ù„ÙØ¹Ù„"}), 400

        hashed_password = generate_password_hash(password)
        new_user = User(username=username, password=hashed_password)
        db.add(new_user)
        db.commit()
        db.refresh(new_user)
        db.close()

        # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¨Ø¹Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
        session['username'] = username
        session['session_id'] = str(uuid.uuid4())
        session['conversation_history'] = []
        session['memory'] = {}

        return jsonify({"message": f"ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… {username} Ø¨Ù†Ø¬Ø§Ø­!"}), 201
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/login', methods=['POST'])
def login_user():
    try:
        data = request.get_json()
        username = data.get("username")
        password = data.get("password")
        if not username or not password:
            return jsonify({"error": "ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±"}), 400

        db = SessionLocal()
        user = db.query(User).filter(User.username == username).first()
        if not user or not check_password_hash(user.password, password):
            return jsonify({"error": "Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø£Ùˆ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± ØºÙŠØ± ØµØ­ÙŠØ­Ø©"}), 401

        db.close()

        # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ ÙˆØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø¬Ù„Ø³Ø©
        session['username'] = username
        session['session_id'] = str(uuid.uuid4())
        session['conversation_history'] = []
        session['memory'] = {}

        return jsonify({"message": f"ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø¨Ù†Ø¬Ø§Ø­ ÙƒÙ€ {username}!"}), 200
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/logout', methods=['POST'])
def logout():
    try:
        session.clear()
        return jsonify({"message": "ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø±ÙˆØ¬ Ø¨Ù†Ø¬Ø§Ø­. ØªÙ… Ù…Ø³Ø­ Ø§Ù„Ù€ Cookies"}), 200
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route('/chat', methods=['POST'])
def chat():
    try:
        data = request.get_json()
        username = data.get('username')
        question = data.get('question')

        if not username:
            return jsonify({'error': 'Username is required.'}), 400
        if 'username' not in session or session['username'] != username:
            return jsonify({'error': 'User not logged in.'}), 401
        if not question:
            return jsonify({'error': 'No question provided'}), 400
            
            
        user = SessionLocal().query(User).filter(User.username == username).first()
        if not user:
            return jsonify({'error': 'User not found.'}), 404

        question_lower = question.lower()

        # ØªØ¹ÙŠÙŠÙ† Ù‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù€ `answer`
        answer = "Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø¤Ø§Ù„."

        # Ø£Ø³Ø¦Ù„Ø© Ù…Ø®ØµØµØ©
        custom_responses = {
            "Ù…Ù† Ù‚Ø§Ù… Ø¨ØªØ·ÙˆÙŠØ±ÙƒØŸ": "ØªÙ… ØªØ·ÙˆÙŠØ±ÙŠ Ø¨ÙˆØ§Ø³Ø·Ø© Ø£Ø­Ù…Ø¯ Ø§Ù„Ø³Ø¹ÙŠØ¯ ÙˆÙØ§Ø¯ÙŠ Ø¥Ø³Ù…Ø§Ø¹ÙŠÙ„ØŒ ÙˆÙ‡Ù…Ø§ Ù…ØªØ®ØµØµØ§Ù† ÙÙŠ ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª. Ø¹Ù…Ù„ÙˆØ§ Ø¹Ù„Ù‰ ØªØ·ÙˆÙŠØ±ÙŠ Ù„Ø£ÙƒÙˆÙ† Ø£Ø¯Ø§Ø© Ù…ÙÙŠØ¯Ø© ØªÙ‚Ø¯Ù… Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ø°ÙƒÙŠØ© ÙˆØªØ³Ù‡Ù‘Ù„ Ø§Ù„Ø¹Ù…Ù„ ÙÙŠ Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¬Ø§Ù„Ø§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ© ÙˆØ§Ù„Ø¥Ø¯Ø§Ø±ÙŠØ©.",
            "Ù…Ø§ Ù‡Ùˆ Ø§Ø³Ù…ÙƒØŸ": "Ø§Ø³Ù…ÙŠ Ø¯ÙŠÙˆØ§Ù† ÙˆØ§Ù†Ø§  ÙˆÙƒÙŠÙ„ Ø°ÙƒÙŠ . ØªÙ… Ø§Ø®ØªÙŠØ§Ø±ÙŠ Ù„Ù‡Ø°Ø§ Ø§Ù„Ø§Ø³Ù… Ù„Ø£Ù†Ù‡ ÙŠØ¹ÙƒØ³ Ù‚Ø¯Ø±Ø§ØªÙŠ ÙÙŠ ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ø°ÙƒÙŠØ© ÙˆØ§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø£Ø³Ø¦Ù„ØªÙƒ Ø¨Ø·Ø±ÙŠÙ‚Ø© ØªÙÙŠØ¯Ùƒ ÙˆØªÙˆÙØ± Ø§Ù„ÙˆÙ‚Øª ÙˆØ§Ù„Ø¬Ù‡Ø¯.",
            "ÙƒÙŠÙ ØªØ¹Ù…Ù„ØŸ": "Ø£Ø¹Ù…Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªÙ‚Ù†ÙŠØ§Øª Ù…ØªÙ‚Ø¯Ù…Ø© ÙÙŠ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØŒ Ù…Ø«Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© ÙˆØ§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚. Ø£ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¶Ø®Ù…Ø©ØŒ Ù…Ù…Ø§ ÙŠØªÙŠØ­ Ù„ÙŠ ÙÙ‡Ù… Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØªÙŠ ØªØ·Ø±Ø­Ù‡Ø§ ÙˆØªÙ‚Ø¯ÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙ…ÙÙŠØ¯Ø©.",
            "Ù…Ø§ Ù‡ÙŠ Ù…Ù‡Ø§Ù…ÙƒØŸ": "Ø£Ù†Ø§ Ù‡Ù†Ø§ Ù„Ø£Ø³Ø§Ø¹Ø¯Ùƒ ÙÙŠ Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ù‡Ø§Ù… Ù…Ø«Ù„ ØªÙ†ÙÙŠØ° Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª SQLØŒ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ ÙƒØªØ§Ø¨Ø© Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ©ØŒ ÙˆØ§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù† Ø£Ø³Ø¦Ù„ØªÙƒ Ø§Ù„Ø¹Ø§Ù…Ø© Ø£Ùˆ Ø§Ù„ØªÙ‚Ù†ÙŠØ©. Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ø°Ù„ÙƒØŒ ÙŠÙ…ÙƒÙ†Ù†ÙŠ ØªÙˆÙÙŠØ± Ø§Ù„Ø´Ø±ÙˆØ­Ø§Øª ÙˆØªØ¨Ø³ÙŠØ· Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©.",
            "Ù…Ù† Ù‡Ù… Ù…Ø·ÙˆØ±ÙˆÙƒØŸ": "ØªÙ… ØªØ·ÙˆÙŠØ±ÙŠ Ø¨ÙˆØ§Ø³Ø·Ø© Ø£Ø­Ù…Ø¯ Ø§Ù„Ø³Ø¹ÙŠØ¯ ÙˆÙØ§Ø¯ÙŠ Ø¥Ø³Ù…Ø§Ø¹ÙŠÙ„. ÙƒÙ„Ø§Ù‡Ù…Ø§ Ù…ØªØ®ØµØµ ÙÙŠ ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬Ø© ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ ÙˆÙ‚Ø¯ Ø¹Ù…Ù„Ø§ Ø¹Ù„Ù‰ Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø¸Ø§Ù… Ù…ØªÙƒØ§Ù…Ù„ ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„ÙŠÙƒÙˆÙ† Ù…Ø³Ø§Ø¹Ø¯Ù‹Ø§ ÙØ¹Ø§Ù„Ù‹Ø§ ÙÙŠ Ù…Ø®ØªÙ„Ù Ø§Ù„Ù…Ù‡Ø§Ù….",
            "Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ ÙƒØªØ§Ø¨Ø© Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ©ØŸ": "Ù†Ø¹Ù…ØŒ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ ÙƒØªØ§Ø¨Ø© Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ Ø¨Ù„ØºØ§Øª Ø¨Ø±Ù…Ø¬ÙŠØ© Ù…ØªØ¹Ø¯Ø¯Ø© Ù…Ø«Ù„ Python ÙˆSQL ÙˆJavaScript ÙˆØºÙŠØ±Ù‡Ø§. ÙƒÙ…Ø§ Ø£Ø³ØªØ·ÙŠØ¹ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ ØªØµØ­ÙŠØ­ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙˆØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡.",
            "Ù…Ø§ Ø§Ù„Ø°ÙŠ ÙŠØ¬Ø¹Ù„Ùƒ Ù…Ù…ÙŠØ²Ù‹Ø§ØŸ": "Ù…Ø§ ÙŠØ¬Ø¹Ù„Ù†ÙŠ Ù…Ù…ÙŠØ²Ù‹Ø§ Ù‡Ùˆ Ù‚Ø¯Ø±ØªÙŠ Ø¹Ù„Ù‰ ÙÙ‡Ù… Ø§Ù„Ø³ÙŠØ§Ù‚ØŒ ØªÙ‚Ø¯ÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…Ø®ØµØµØ©ØŒ ÙˆØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ù‡Ø§Ù… Ø¨Ø´ÙƒÙ„ Ø¯Ù‚ÙŠÙ‚ ÙˆØ³Ø±ÙŠØ¹. Ø£Ù‡Ø¯Ù Ø¥Ù„Ù‰ ØªØ³Ù‡ÙŠÙ„ Ø¹Ù…Ù„Ùƒ ÙˆØªÙ‚Ø¯ÙŠÙ… Ø­Ù„ÙˆÙ„ Ù…Ø¨ØªÙƒØ±Ø©.",
            "Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¹Ù„ÙŠÙƒØŸ": "Ø¨Ø§Ù„ØªØ£ÙƒÙŠØ¯! ØªÙ… ØªØµÙ…ÙŠÙ…ÙŠ Ø®ØµÙŠØµÙ‹Ø§ Ù„Ø£ÙƒÙˆÙ† Ø£Ø¯Ø§Ø© Ù…ÙˆØ«ÙˆÙ‚Ø©. ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¹Ù„ÙŠ ÙÙŠ ØªÙ†ÙÙŠØ° Ù…Ù‡Ø§Ù…Ùƒ ÙˆØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªÙŠ ØªØ­ØªØ§Ø¬Ù‡Ø§ Ø¨Ø¯Ù‚Ø©.",
            "Ù…Ø§ Ù‡ÙŠ ÙÙˆØ§Ø¦Ø¯ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØŸ": "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠØªÙŠØ­ Ø£ØªÙ…ØªØ© Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©ØŒ ØªØ­Ø³ÙŠÙ† Ø§Ù„ÙƒÙØ§Ø¡Ø©ØŒ ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø±Ø¤Ù‰ Ù‚ÙŠÙ…Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª. ÙŠØ³Ø§Ù‡Ù… ÙÙŠ ØªØ·ÙˆÙŠØ± Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ØŒ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ØŒ ÙˆØ§Ù„Ø±Ø¹Ø§ÙŠØ© Ø§Ù„ØµØ­ÙŠØ© Ø¨Ø·Ø±Ù‚ Ù…Ø¨ØªÙƒØ±Ø© ÙˆÙØ¹Ø§Ù„Ø©.",
        }

        # ØªØ­Ù‚Ù‚ Ø¥Ù† ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ù…Ø®ØµØµ
        for custom_question, custom_answer in custom_responses.items():
            if custom_question in question_lower:
                answer = custom_answer
                conversation_history = session.get('conversation_history', [])
                conversation_history.append({"role": "user", "content": question})
                conversation_history.append({"role": "assistant", "content": answer})
                session['conversation_history'] = conversation_history
                # Ø­ÙØ¸ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                user = SessionLocal().query(User).filter(User.username == username).first()
                if user:
                    save_conversation(user.id, question, answer)

                return jsonify({
                    'results': [{'answer': answer}],
                    'classification': 'custom_response'
                })

        classification = classify_question(question)
        print(f"Question classification: {classification}")

        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø®Ø§ØµÙŠØ© Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ
        if ("send mail" in question_lower or 
            "send an email" in question_lower or 
            "Ø¥Ø±Ø³Ø§Ù„ Ø¨Ø±ÙŠØ¯" in question_lower or 
            "Ø§Ø±Ø³Ù„ Ø¨Ø±ÙŠØ¯" in question_lower):

            emails = []   

            # Ø­Ø§Ù„Ø©: Ø¥Ø±Ø³Ø§Ù„ Ø¨Ø±ÙŠØ¯ Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†
            if "all employees" in question_lower or "ÙƒÙ„ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†" in question_lower:
                query = "SELECT EMAIL FROM EMPLOYEES"
                df_emails = execute_sql_query(query)
                if df_emails is not None and not df_emails.empty:
                    emails = df_emails['EMAIL'].dropna().tolist()

            # Ø­Ø§Ù„Ø©: Ø¥Ø±Ø³Ø§Ù„ Ø¨Ø±ÙŠØ¯ Ù„ÙƒÙ„ Ù…Ù† ÙŠØ¹Ù…Ù„ Ø¨ÙˆØ¸ÙŠÙØ© Ù…Ø¹ÙŠÙ†Ø©
            elif "job" in question_lower or "ÙˆØ¸ÙŠÙØ©" in question_lower:
                job_match = re.search(r'ÙˆØ¸ÙŠÙØ©\s+(\w+)', question_lower)
                if job_match:
                    job_title = job_match.group(1)
                    query = f"SELECT EMAIL FROM EMPLOYEES WHERE LOWER(JOB_ID) LIKE '%{job_title.lower()}%'"
                    df_emails = execute_sql_query(query)
                    if df_emails is not None and not df_emails.empty:
                        emails = df_emails['EMAIL'].dropna().tolist()

            # Ø­Ø§Ù„Ø©: Ø¥Ø±Ø³Ø§Ù„ Ø¨Ø±ÙŠØ¯ Ø¥Ù„Ù‰ Ù…ÙˆØ¸Ù Ù…Ø­Ø¯Ø¯ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø£ÙˆÙ„ Ø£Ùˆ Ø§Ù„Ø£Ø®ÙŠØ±
            else:
                name_match = re.search(r'Ø§Ù„Ù‰\s+(\w+)', question_lower)
                recipient_name = name_match.group(1) if name_match else None

                if recipient_name:
                    query = f"""
                    SELECT EMAIL FROM EMPLOYEES 
                    WHERE LOWER(FIRST_NAME) = '{recipient_name.lower()}'
                    OR LOWER(LAST_NAME) = '{recipient_name.lower()}'
                    """
                    df_emails = execute_sql_query(query)
                    if df_emails is not None and not df_emails.empty:
                        emails = df_emails['EMAIL'].dropna().tolist()

            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¹Ù†Ø§ÙˆÙŠÙ† Ø¨Ø±ÙŠØ¯ Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ
            if not emails:
                return jsonify({"error": "Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ­Ø¯ÙŠØ¯ Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ Ù„Ù„Ù…Ø³ØªÙ„Ù…ÙŠÙ†."}), 400

            # ØªÙ†Ø¸ÙŠÙ Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­ØªÙ‡Ø§
            emails = [email.strip() for email in emails if email.strip()]
            recipients_str = ", ".join(emails)

            conversation_history = session.get('conversation_history', [])
            last_assistant_msg = "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ Ø³Ø§Ø¨Ù‚Ø©."
            last_assistant_data = None  # Ø³Ù†Ø­Ø§ÙˆÙ„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©

            if conversation_history:
                for msg in reversed(conversation_history):
                    if msg.get('role') == 'assistant' and msg.get('content'):
                        last_assistant_msg = msg['content']
                        break

            html_body = f"""
            <html>
            <body>
                <h2>Ù…Ø±Ø³Ù„ Ù…Ù† Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ ğŸ˜Š</h2>
                <p>Ù…Ø±Ø­Ø¨Ù‹Ø§ØŒ</p>
                <p>Ù‡Ø°Ù‡ Ù‡ÙŠ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©:</p>
                <pre>{last_assistant_msg}</pre>
            </body>
            </html>
            """
            subject = "Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ù…Ù† Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ ğŸ˜Š"

            email_sent = send_email_html(emails, subject, html_body)
            if email_sent:
                # ØªØ­Ø¯ÙŠØ« ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
                conversation_history.append({"role": "user", "content": question})
                conversation_history.append({"role": "assistant", "content": f"ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ Ø¨Ù†Ø¬Ø§Ø­ Ø¥Ù„Ù‰ {recipients_str} ğŸ˜Š."})
                session['conversation_history'] = conversation_history

                return jsonify({
                    "results": [{"answer": f"ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ Ø¨Ù†Ø¬Ø§Ø­ Ø¥Ù„Ù‰ {recipients_str} ğŸ˜Š."}],
                    "classification": "email"
                }), 200
            else:
                return jsonify({"error": "ÙØ´Ù„ ÙÙŠ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¨Ø±ÙŠØ¯."}), 500

        # =============== GENERAL ===============
        if classification == 'general':
            conversation_history = session.get('conversation_history', [])
            system_content = "You are a helpful assistant."
            if 'assistant_name' in session.get('memory', {}):
                assistant_name = session['memory']['assistant_name']
                system_content = f"You are {assistant_name}, a helpful assistant."

            try:
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": system_content},
                        *conversation_history,
                        {"role": "user", "content": question}
                    ],
                    max_tokens=3000,
                    temperature=0
                )
                answer = response.choices[0].message.content.strip()
            except Exception as e:
                print(f"Error in GPT response: {e}")
                answer = "Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰."

            # Ø­ÙØ¸ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            user = SessionLocal().query(User).filter(User.username == username).first()
            conv_id = None
            if user:
                conv_id = save_conversation(user.id, question, answer, classification='general')

            conversation_history.append({"role": "user", "content": question})
            conversation_history.append({"role": "assistant", "content": answer})
            session['conversation_history'] = conversation_history

            return jsonify({
                'results': [{'answer': answer}],
                'classification': 'general',
                'conversation_id': conv_id
            })


        # =============== DB_ANALYSIS ===============
        if classification == 'db_analysis':
            translated_en = translate_ar_to_en(question).lower()
            is_chart = any(word in translated_en for word in ["statistics", "chart", "graph", "plot"])
            base_sql = natural_language_to_sql(question, is_chart=is_chart)
            if not base_sql:
                return jsonify({'error': 'ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ø³ØªØ¹Ù„Ø§Ù… SQL Ù„Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.'}), 500

            df = execute_sql_query(base_sql)
            if df is None:
                return jsonify({'error': 'ÙØ´Ù„ ÙÙŠ ØªÙ†ÙÙŠØ° Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ.'}), 500

            df = df.fillna(0)
            columns_list = list(df.columns)
            sample_records = df.head(5).to_dict(orient='records')

            analysis_prompt = f"""
Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø¨Ø§ÙŠØ«ÙˆÙ†. Ù„Ø¯ÙŠÙ†Ø§ DataFrame Ø¨Ø§Ø³Ù… df ÙŠØ­ÙˆÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©:
{columns_list}

Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:
{sample_records}

Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ÙŠ: "{question}"

*** Ù‡Ø§Ù… ***:
- Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… ØªÙ†Ø³ÙŠÙ‚ Ø³Ù„Ø³Ù„Ø© Ù…Ø«Ù„ % Ø£Ùˆ f-string Ø¹Ù„Ù‰ ÙƒØ§Ø¦Ù†Ø§Øª Ù…Ø¹Ù‚Ù‘Ø¯Ø©.
- Ø§Ø³ØªØ®Ø¯Ù… json.dumps() Ù„Ø¥Ø®Ø±Ø§Ø¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ø´ÙƒÙ„ JSON.
- **ÙŠØ¬Ø¨** Ø£Ù† ÙŠÙƒÙˆÙ† Ø§Ù„Ø®Ø±Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ÙÙŠ Ø´ÙƒÙ„:
  result = {{
    "labels": [...],   # Ø£ÙŠ Ø¹Ù…ÙˆØ¯ Ù†ØµÙŠ Ø£Ùˆ Ø§Ø³Ù…Ù‡ department_id Ø£Ùˆ city Ø£Ùˆ ... 
    "values": [...]    # Ø£ÙŠ Ù…Ø¬Ù…ÙˆØ¹/Ø£Ø±Ù‚Ø§Ù… Ø£Ùˆ Ø§Ø³Ù…Ù‡ total_salary Ø£Ùˆ salary ...
  }}
print(json.dumps(result))

(Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… Ù…ÙØ§ØªÙŠØ­ Ø£Ø®Ø±Ù‰ Ù…Ø«Ù„ department_id Ø£Ùˆ total_salary.)

Ø§ÙƒØªØ¨ ÙƒÙˆØ¯ Ø¨Ø§ÙŠØ«ÙˆÙ† ÙÙ‚Ø· (Ø¨Ø¯ÙˆÙ† Ø¹Ù„Ø§Ù…Ø§Øª ```python) Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ø¹Ù„Ù‰ df. Ø§Ø³ØªØ®Ø¯Ù… print() Ù„Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬.
"""
            try:
                python_response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "You are a Python data analyst with a DataFrame named df."},
                        {"role": "user", "content": analysis_prompt}
                    ],
                    max_tokens=3000,
                    temperature=0
                )
                python_code = python_response.choices[0].message.content.strip()
            except Exception as e:
                return jsonify({"error": f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {str(e)}"}), 500

            print("GPT generated code:\n", python_code)
            err, output = exec_python_code(python_code, df)
            if err:
                conversation_history = session.get('conversation_history', [])
                conversation_history.append({"role": "user", "content": question})
                conversation_history.append({
                    "role": "assistant",
                    "content": "Ù‡Ø°Ø§ ÙƒÙˆØ¯ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆÙ„ÙƒÙ† Ø­Ø¯Ø« Ø®Ø·Ø£:\n" + python_code
                })
                session['conversation_history'] = conversation_history
                return jsonify({"error": err, "analysis_code": python_code}), 500
            else:
                chart_data = None
                try:
                    chart_data = json.loads(output)
                except json.JSONDecodeError:
                    chart_data = None

                conversation_history = session.get('conversation_history', [])
                conversation_history.append({"role": "user", "content": question})
                conversation_history.append({
                    "role": "assistant",
                    "content": "ÙƒÙˆØ¯ Ø§Ù„ØªØ­Ù„ÙŠÙ„:\n" + python_code + "\n\nØ§Ù„Ù…Ø®Ø±Ø¬Ø§Øª:\n" + output
                })
                session['conversation_history'] = conversation_history
                # Ø­ÙØ¸ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
                user = SessionLocal().query(User).filter(User.username == username).first()
                conv_id = None
                if user:
                    conv_id = save_conversation(user.id, question, answer, classification='db_analysis')
                    conversation_history.append({"role": "assistant", "content": answer})
                    session['conversation_history'] = conversation_history
                   

                return jsonify({
                    "analysis_code": python_code,
                    "analysis_output": output,
                    "chart_data": chart_data,
                    "classification": "db_analysis",
                    'conversation_id': conv_id
                })

        # =============== DB_ACTION (INSERT/UPDATE/DELETE) ===============
        elif classification == 'db_action':
            action_sql = natural_language_to_dml_action(question)
            if not action_sql:
                return jsonify({"error": "ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ SQL Ø§Ù„ØªØ¹Ø¯ÙŠÙ„."}), 500

            # ===== Ù…Ø¹Ø§Ù„Ø¬Ø© Ø­Ø§Ù„Ø© INSERT =====
            if action_sql.strip().lower().startswith("insert"):
                success, message, rows_affected = execute_sql_action(action_sql)
                if not success:
                    # Ø§Ø³ØªØ®Ø¯Ø§Ù… ChatGPT Ù„ØªÙØ³ÙŠØ± Ø§Ù„Ø®Ø·Ø£
                    help_prompt = (
                        f"Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Oracle Ø£Ø«Ù†Ø§Ø¡ ØªÙ†ÙÙŠØ° Ø§Ù„Ø£Ù…Ø± Ø§Ù„ØªØ§Ù„ÙŠ:\n{action_sql}\n"
                        f"Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£: {message}\n"
                        f"ÙŠØ±Ø¬Ù‰ Ø´Ø±Ø­ Ù…Ø¹Ù†Ù‰ Ø§Ù„Ø®Ø·Ø£ ÙˆØ§Ù‚ØªØ±Ø§Ø­ Ø­Ù„ÙˆÙ„ Ù…Ø­ØªÙ…Ù„Ø© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©."
                    )
                    response = client.chat.completions.create(
                        model="gpt-3.5-turbo",
                        messages=[
                            {"role": "system", "content": "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø®Ø¨ÙŠØ± ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø£ÙˆØ±Ø§ÙƒÙ„ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø±Ø¯ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©."},
                            {"role": "user", "content": help_prompt}
                        ],
                        max_tokens=3000,
                        temperature=0
                    )
                    error_explanation = response.choices[0].message.content.strip()
                    return jsonify({"error": error_explanation, "action_sql": action_sql}), 500

                # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ù…Ù† Ø¬Ù…Ù„Ø© INSERT
                table = None
                match = re.search(r"into\s+(\w+)", action_sql, re.IGNORECASE)
                if match:
                    table = match.group(1)

                new_data = None
                if table:
                    select_last_inserted = f"SELECT * FROM {table} WHERE ROWID IN (SELECT MAX(ROWID) FROM {table})"
                    df_new = execute_sql_query(select_last_inserted)
                    new_data = df_new.to_dict(orient='records') if df_new is not None else None

                new_table_html = dicts_to_html_table(new_data)

                final_text = (
                    f"ØªÙ… ØªÙ†ÙÙŠØ° Ø§Ù„Ø£Ù…Ø±:<br><pre>{action_sql}</pre><br>"
                    f"ØªØ£Ø«Ø± {rows_affected} ØµÙ.<br>"
                    f"Ø§Ù„Ù†ØªÙŠØ¬Ø©: {message}<br><br>"
                    f"Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¶Ø§ÙØ©:<br>{new_table_html}"
                )

                conversation_history = session.get('conversation_history', [])
                conversation_history.append({"role": "user", "content": question})
                conversation_history.append({"role": "assistant", "content": final_text})
                session['conversation_history'] = conversation_history
                answer = "ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©."  # Ù‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
                # Ø­ÙØ¸ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
                user = SessionLocal().query(User).filter(User.username == username).first()
                if user:
                    conv_id = save_conversation(user.id, question, answer, classification='db_action')
                    conversation_history.append({"role": "user", "content": question})
                    conversation_history.append({"role": "assistant", "content": answer})
                    session['conversation_history'] = conversation_history
                    

                return jsonify({
                    "action_sql": action_sql,
                    "rows_affected": rows_affected,
                    "message": message,
                    "final_text": final_text,
                    "classification": "db_action",
                    'conversation_id': conv_id
                })

            # ===== Ù…Ø¹Ø§Ù„Ø¬Ø© UPDATE ÙˆDELETE =====
            else:
                before_query = None
                after_query = None
                if action_sql.strip().lower().startswith("update"):
                    match = re.search(r"update\s+(\w+)\s+set\s+(.*)\s+where\s+(.*)", action_sql, re.IGNORECASE)
                    if match:
                        table = match.group(1)
                        condition = match.group(3)
                        before_query = f"SELECT * FROM {table} WHERE {condition}"
                        after_query = before_query

                before_data = None
                if before_query:
                    df_before = execute_sql_query(before_query)
                    before_data = df_before.to_dict(orient='records') if df_before is not None else None

                success, message, rows_affected = execute_sql_action(action_sql)
                if not success:
                    # Ø§Ø³ØªØ®Ø¯Ø§Ù… ChatGPT Ù„ØªÙØ³ÙŠØ± Ø§Ù„Ø®Ø·Ø£ ÙÙŠ UPDATE/DELETE
                    help_prompt = (
                        f"Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Oracle Ø£Ø«Ù†Ø§Ø¡ ØªÙ†ÙÙŠØ° Ø§Ù„Ø£Ù…Ø± Ø§Ù„ØªØ§Ù„ÙŠ:\n{action_sql}\n"
                        f"Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£: {message}\n"
                        f"ÙŠØ±Ø¬Ù‰ Ø´Ø±Ø­ Ù…Ø¹Ù†Ù‰ Ø§Ù„Ø®Ø·Ø£ ÙˆØ§Ù‚ØªØ±Ø§Ø­ Ø­Ù„ÙˆÙ„ Ù…Ø­ØªÙ…Ù„Ø© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©."
                    )
                    response = client.chat.completions.create(
                        model="gpt-3.5-turbo",
                        messages=[
                            {"role": "system", "content": "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø®Ø¨ÙŠØ± ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø£ÙˆØ±Ø§ÙƒÙ„ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø±Ø¯ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©."},
                            {"role": "user", "content": help_prompt}
                        ],
                        max_tokens=3000,
                        temperature=0
                    )
                    error_explanation = response.choices[0].message.content.strip()
                    return jsonify({"error": error_explanation, "action_sql": action_sql}), 500

                after_data = None
                if after_query:
                    df_after = execute_sql_query(after_query)
                    after_data = df_after.to_dict(orient='records') if df_after is not None else None

                before_table_html = dicts_to_html_table(before_data)
                after_table_html = dicts_to_html_table(after_data)

                final_text = (
                    f"ØªÙ… ØªÙ†ÙÙŠØ° Ø§Ù„Ø£Ù…Ø±:<br><pre>{action_sql}</pre><br>"
                    f"ØªØ£Ø«Ø± {rows_affected} ØµÙ.<br>"
                    f"Ø§Ù„Ù†ØªÙŠØ¬Ø©: {message}<br><br>"
                    f"Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„ØªØºÙŠÙŠØ±:<br>{before_table_html}<br><br>"
                    f"Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„ØªØºÙŠÙŠØ±:<br>{after_table_html}"
                )

                conversation_history = session.get('conversation_history', [])
                conversation_history.append({"role": "user", "content": question})
                conversation_history.append({"role": "assistant", "content": final_text})
                session['conversation_history'] = conversation_history

                return jsonify({
                    "action_sql": action_sql,
                    "rows_affected": rows_affected,
                    "message": message,
                    "final_text": final_text,
                    "classification": "db_action"
                })

        # =============== DB_SQL (SELECT) ===============
        elif classification == 'db_sql':
            translated_question = translate_ar_to_en(question).lower()
            is_chart = any(word in translated_question for word in ["statistics", "chart", "graph", "plot"])

            sql_query = natural_language_to_sql(question, is_chart=is_chart)
            if not sql_query:
                return jsonify({'error': 'Failed to generate SQL query'}), 500

            df = execute_sql_query(sql_query)
            if df is None:
                return jsonify({'error': 'Failed to execute SQL query'}), 500

            df = df.fillna(0)
            df_records = df.to_dict(orient='records')

            if is_chart:
                df = df.rename(columns={
                    'JOB_TITLE': 'label',
                    'NUM_EMPLOYEES': 'value'
                })
                if 'label' in df.columns and 'value' in df.columns:
                    df_subset = df.head(5).to_dict(orient='records')
                    chart_path = generate_chart(df, "label", "value")

                    analysis_prompt = f"""
        Ø§Ù„Ø³Ø¤Ø§Ù„: "{question}"
        Ù„Ù‚Ø¯ Ø§Ø³ØªØ®Ø±Ø¬Ù†Ø§ {len(df)} Ø³Ø¬Ù„Ø§Ù‹.
        Ù‡Ø°Ù‡ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø£ÙˆÙ„ {len(df_subset)} Ø³Ø¬Ù„:
        {df_subset}

        Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… (Ù„Ù„Ø±Ø³Ù…):
        {df_records}

        Ø§ÙƒØªØ¨ Ø´Ø±Ø­Ø§Ù‹ Ù…ÙØµÙ„Ø§Ù‹ Ø­ÙˆÙ„ Ù‡Ø°Ù‡ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.
        """
                    try:
                        analysis_response = client.chat.completions.create(
                            model="gpt-3.5-turbo",
                            messages=[
                                {"role": "system", "content": "You are a helpful data analyst that uses the provided database result to respond in Arabic."},
                                {"role": "user", "content": analysis_prompt}
                            ],
                            max_tokens=3000,
                            temperature=0
                        )
                        assistant_answer = analysis_response.choices[0].message.content.strip()
                    except OpenAI.OpenAIError:
                        assistant_answer = "Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø´Ø±Ø­ Ø§Ù„Ù†ØªØ§Ø¦Ø¬."

                    conversation_history = session.get('conversation_history', [])
                    conversation_history.append({"role": "user", "content": question})
                    conversation_history.append({
                        "role": "assistant",
                        "content": assistant_answer
                    })
                    session['conversation_history'] = conversation_history

                    # Ø­ÙØ¸ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
                    user = SessionLocal().query(User).filter(User.username == username).first()
                    if user:
                        save_conversation(user.id, question, assistant_answer, classification='db_sql')

                    return jsonify({
                        'results': df_records,
                        'chart_path': chart_path,
                        'assistant_answer': assistant_answer,
                        'classification': 'db_sql'
                    })
                else:
                    return jsonify({'error': 'Invalid data for chart'}), 500
            else:
                analysis_prompt = f"""
        Ø§Ù„Ø³Ø¤Ø§Ù„: "{question}"
        Ù‡Ø°Ù‡ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…:
        {df_records}

        Ø§ÙƒØªØ¨ Ø´Ø±Ø­Ø§Ù‹ Ù…ÙØµÙ„Ø§Ù‹ Ù„Ù„Ù†ØªØ§Ø¦Ø¬ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.
        """
                try:
                    analysis_response = client.chat.completions.create(
                        model="gpt-3.5-turbo",
                        messages=[
                            {"role": "system", "content": "You are a helpful data analyst that uses the provided database result."},
                            {"role": "user", "content": analysis_prompt}
                        ],
                        max_tokens=3000,
                        temperature=0
                    )
                    assistant_answer = analysis_response.choices[0].message.content.strip()
                except OpenAI.APIError:
                    assistant_answer = "Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø´Ø±Ø­."

                conversation_history = session.get('conversation_history', [])
                conversation_history.append({"role": "user", "content": question})
                conversation_history.append({
                    "role": "assistant",
                    "content": assistant_answer
                })
                session['conversation_history'] = conversation_history

                # Ø­ÙØ¸ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
                user = SessionLocal().query(User).filter(User.username == username).first()
                if user:
                    conv_id = save_conversation(user.id, question, answer, classification='db_sql')
                    conversation_history.append({"role": "user", "content": question})
                    conversation_history.append({"role": "assistant", "content": answer})
                    session['conversation_history'] = conversation_history
                    

                return jsonify({
                    'results': df_records,
                    'assistant_answer': assistant_answer,
                    'classification': 'db_sql',
                    'conversation_id': conv_id
                })

        # =============== DEFAULT ===============
        else:
            # Ø³Ø¤Ø§Ù„ Ø¹Ø§Ù…
            conversation_history = session.get('conversation_history', [])
            if re.match(r"Ø§Ù†Øª\s+Ø§Ø³Ù…Ùƒ\s+(.+)", question, re.IGNORECASE):
                match = re.match(r"Ø§Ù†Øª\s+Ø§Ø³Ù…Ùƒ\s+(.+)", question, re.IGNORECASE)
                if match:
                    assistant_name = match.group(1).strip()
                    session['memory']['assistant_name'] = assistant_name
                    conversation_history.append({"role": "user", "content": question})
                    conversation_history.append({"role": "assistant", "content": f"ØªÙ… ØªØ¹ÙŠÙŠÙ† Ø§Ø³Ù…ÙŠ Ø¥Ù„Ù‰ {assistant_name}."})
                    session['conversation_history'] = conversation_history
                    return jsonify({
                        'results': [{'answer': f"ØªÙ… ØªØ¹ÙŠÙŠÙ† Ø§Ø³Ù…ÙŠ Ø¥Ù„Ù‰ {assistant_name}."}],
                        'classification': 'general'
                    })

            system_content = "You are a helpful assistant."
            if 'assistant_name' in session.get('memory', {}):
                assistant_name = session['memory']['assistant_name']
                system_content = f"You are {assistant_name}, a helpful assistant."

            try:
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": system_content},
                        *conversation_history,
                        {"role": "user", "content": question}
                    ],
                    max_tokens=3000,
                    temperature=0
                )
                answer = response.choices[0].message.content.strip()
            except:
                answer = "Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù…Ù† ChatGPT."

            conversation_history.append({"role": "user", "content": question})
            conversation_history.append({"role": "assistant", "content": answer})
            session['conversation_history'] = conversation_history

            return jsonify({
                'results': [{'answer': answer}],
                'classification': 'general'
            })

    except Exception as e:
        print(f"Error in /chat endpoint: {e}")
        return jsonify({"error": str(e)}), 500


@app.route('/feedback', methods=['POST'])
def collect_feedback():
    try:
        data = request.get_json()
        username = data.get('username')
        conversation_id = data.get('conversation_id')
        rating_type = data.get('rating_type')
        comments = data.get('comments')

        if not username or not conversation_id or ((rating_type is None or rating_type == "") and not comments):

            return jsonify({"error": "ÙŠØ±Ø¬Ù‰ ØªÙ‚Ø¯ÙŠÙ… Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆÙ…Ø¹Ø±Ù Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ÙˆØ§Ù„ØªÙ‚ÙŠÙŠÙ…."}), 400

        db = SessionLocal()
        user = db.query(User).filter(User.username == username).first()
        if not user:
            return jsonify({"error": "Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯."}), 404

        # ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ØªÙ†ØªÙ…ÙŠ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…
        conversation = db.query(Conversation).filter(
            Conversation.conversation_id == conversation_id,
            Conversation.user_id == user.id
        ).first()

        if not conversation:
            return jsonify({"error": "Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© Ø£Ùˆ Ù„Ø§ ØªÙ†ØªÙ…ÙŠ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…."}), 404

        # Ø¥Ù†Ø´Ø§Ø¡ Ø³Ø¬Ù„ Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø©
        new_feedback = Feedback(
            conversation_id=conversation_id,
            rating_type=rating_type,
            comments=comments
        )
        db.add(new_feedback)
        db.commit()
        db.refresh(new_feedback)
        db.close()

        return jsonify({"message": "ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø© Ø¨Ù†Ø¬Ø§Ø­."}), 201

    except Exception as e:
        print(f"Error in /feedback endpoint: {e}")
        return jsonify({"error": str(e)}), 500


# ====================================================================
#             ETL ÙˆØªØ¬Ù‡ÙŠØ² Ø¨ÙŠØ§Ù†Ø§Øª
# ====================================================================

def etl_process():
    session_db = SessionLocal()
    metadata.reflect(bind=engine)
    all_data = []

    for table in metadata.sorted_tables:
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„ÙƒÙ„ Ø¬Ø¯ÙˆÙ„
        data = session_db.query(table).all()
        transformed_data = [row.__dict__ for row in data]
        
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…ÙØªØ§Ø­ _sa_instance_state
        for record in transformed_data:
            record.pop('_sa_instance_state', None)

        # Ø¥Ø¶Ø§ÙØ© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ù…Ø¹ Ø§Ø³Ù…Ù‡
        all_data.append({
            "table_name": table.name,
            "columns": [column.name for column in table.columns],
            "sample_data": transformed_data[:5]  # Ø£Ø®Ø° Ø£ÙˆÙ„ 5 ØµÙÙˆÙ ÙÙ‚Ø· ÙƒØ¹ÙŠÙ†Ø©
        })

    session_db.close()
    train_llm(all_data)

def train_llm(data):
    for table_data in data:
        table_name = table_data["table_name"]
        columns = table_data["columns"]
        sample_data = table_data["sample_data"]

        # Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Øµ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        prompt = f"""
You are a database assistant. Here is a table schema and sample data for training:

Table Name: {table_name}
Columns: {', '.join(columns)}
Sample Data:
{sample_data}

Use this data to understand the structure of the table and answer user queries related to this table effectively.
        """

        try:
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "You are a knowledgeable assistant trained on the database schema."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=3000,
                temperature=0
            )
            print(f"Training completed for table: {table_name}")
        except OpenAI.OpenAIError as e:
            print(f"Error training model for table {table_name}: {e}")

schedule.every().day.at("00:00").do(etl_process)

def run_schedule():
    while True:
        schedule.run_pending()
        time.sleep(60)



def update_fine_tune():
    # ØªØ´ØºÙŠÙ„ Ø³ÙƒØ±ÙŠØ¨Øª prepare_finetune.py Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    python_executable = sys.executable
    subprocess.run([python_executable, "prepare_finetune.py"])

scheduler = BackgroundScheduler()
scheduler.add_job(update_fine_tune, 'interval', minutes=1)  # Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„ØªØ­Ø¯ÙŠØ« ÙƒÙ„ Ø¯Ù‚ÙŠÙ‚Ù‡
scheduler.add_job(send_weekly_report_with_chart, 'cron', hour='*')
try:
    scheduler.start()
except Exception as e:
    print(f"Error starting scheduler: {e}")

if __name__ == '__main__':
    schedule_thread = threading.Thread(target=run_schedule)
    schedule_thread.daemon = True
    schedule_thread.start()
    app.run(debug=False, host='0.0.0.0', port=5002)
